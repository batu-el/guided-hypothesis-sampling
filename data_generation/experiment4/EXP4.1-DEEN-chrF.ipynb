{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_PATH = ''\n",
    "import jsonlines\n",
    "data_PATH = drive_PATH + 'data1000/exp2.1.deen-n128-t1-e0.02.jsonl'\n",
    "data = []\n",
    "\n",
    "with jsonlines.open(data_PATH) as f:\n",
    "    for line in f.iter():\n",
    "        data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import jsonlines\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Eval - BLEURT\n",
    "# from datasets import load_metric\n",
    "# bleurt = load_metric(\"bleurt\", module_type=\"metric\")\n",
    "# Eval - chrf(++)\n",
    "import evaluate\n",
    "chrf = evaluate.load(\"chrf\") # (word_order=2) for chrf++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def BLEURT_mbrd(candidates):\n",
    "#   k_samples = len(candidates)\n",
    "#   score_matrix = np.zeros((k_samples, k_samples))\n",
    "\n",
    "#   for j1 in range(k_samples):\n",
    "#     references=[candidates[j1][0] for j2 in range(k_samples)]\n",
    "#     predictions=[candidates[j2][0] for j2 in range(k_samples)]\n",
    "#     scores = bleurt.compute(predictions=predictions, references=references)['scores']\n",
    "#     score_matrix[ : ,j1] = scores\n",
    "\n",
    "#   # remove votes for self\n",
    "#   for j1 in range(k_samples):\n",
    "#     for j2 in range(k_samples):\n",
    "#       if j1 == j2:\n",
    "#         score_matrix[j2,j1] = 0\n",
    "\n",
    "#   sum_scores = np.sum(score_matrix, axis=1)\n",
    "#   index = np.argmax(sum_scores)\n",
    "#   mbr_winner = candidates[index]\n",
    "\n",
    "#   return mbr_winner, index, sum_scores, score_matrix\n",
    "\n",
    "def CHARF_mbrd(candidates):\n",
    "  k_samples = len(candidates)\n",
    "  score_matrix = np.zeros((k_samples, k_samples))\n",
    "\n",
    "  for j1 in range(k_samples):\n",
    "    for j2 in range(k_samples):\n",
    "      references=[candidates[j1][0]]\n",
    "      predictions=[candidates[j2][0]]\n",
    "      scores = chrf.compute(predictions=predictions, references=references, word_order=2)['score']\n",
    "      score_matrix[j2,j1] = scores\n",
    "\n",
    "  # remove votes for self\n",
    "  for j1 in range(k_samples):\n",
    "    for j2 in range(k_samples):\n",
    "      if j1 == j2:\n",
    "        score_matrix[j2,j1] = 0\n",
    "\n",
    "  sum_scores = np.sum(score_matrix, axis=1)\n",
    "  index = np.argmax(sum_scores)\n",
    "  mbr_winner = candidates[index]\n",
    "\n",
    "  return mbr_winner, index, sum_scores, score_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'DEEN'\n",
    "dataset = data\n",
    "num_examples = 1000\n",
    "num_candidates = 128\n",
    "assert(num_examples == len(dataset))\n",
    "for j in tqdm.tqdm(range(num_examples)):\n",
    "    predictions=[dataset[j]['candidates'][i][0] for i in range(num_candidates)]\n",
    "    references=[dataset[j]['ref'] for i in range(num_candidates)]\n",
    "    \n",
    "    chrf_scores = []\n",
    "    for i in range(num_candidates):\n",
    "        chrf_scores.append(chrf.compute(predictions=[predictions[i]], references=[references[i]], word_order=2)['score'])\n",
    "    dataset[j]['CHRF_cand_scores'] = np.array(chrf_scores, dtype=float).tolist()\n",
    "    # MBR CHRF\n",
    "    mbr_winner, index, sum_scores, score_matrix = CHARF_mbrd(dataset[j]['candidates'])\n",
    "    dataset[j]['MBR_CHRF_winner'] = mbr_winner\n",
    "    dataset[j]['MBR_CHRF_winner_index'] = int(index)\n",
    "    dataset[j]['MBR_CHRF_cand_scores'] = sum_scores.tolist()\n",
    "    dataset[j]['MBR_CHRF_score_matrix'] = score_matrix.tolist()\n",
    "\n",
    "chrf_dataset_PATH = drive_PATH+ f'data1000/chrf-{dataset_name}.jsonl'\n",
    "with jsonlines.open(chrf_dataset_PATH, mode='w') as writer:\n",
    "    for item in dataset:\n",
    "        writer.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
