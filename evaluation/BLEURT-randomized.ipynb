{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlIEOFTPMKr9",
    "outputId": "51191e9e-8439-4a20-8b25-dd538d122ed0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "drive_PATH = '../content/drive/MyDrive/Colab Notebooks/l101.experiments.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTvfseAtNHWG",
    "outputId": "8e21e224-7210-4d8e-ef38-1ace80d4aa3b"
   },
   "outputs": [],
   "source": [
    "!pip install jsonlines scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oB-A_3y9NQlz"
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "# DATA_NAME = 'DEEN'\n",
    "DATA_NAME = 'ENDE'\n",
    "# DATA_NAME = 'ENTR'\n",
    "# DATA_NAME = 'TREN'\n",
    "DATA_PATH = drive_PATH + f'/data-main/{DATA_NAME}.jsonl'\n",
    "DATA = []\n",
    "with jsonlines.open(DATA_PATH) as f:\n",
    "    for line in f.iter():\n",
    "        DATA.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MW-hchCwPw_Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLgry03kQAMN"
   },
   "outputs": [],
   "source": [
    "num_datapoints = 1000\n",
    "reduced_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqI3l5TbQNYh",
    "outputId": "839ca406-8fe9-4d9c-bf5d-26bb01b3fdff"
   },
   "outputs": [],
   "source": [
    "# Encoded Data\n",
    "enc_candidates = []\n",
    "enc_candidates10 = []\n",
    "# Scores\n",
    "BLEURT_cand_scores = []\n",
    "CHRF_cand_scores = []\n",
    "# chrF++ Scores\n",
    "MBR_BLEURT_cand_scores = []\n",
    "MBR_CHRF_cand_scores = []\n",
    "# Winner Indexes\n",
    "MBR_BLEURT_winner_index = []\n",
    "MBR_CHRF_winner_index = []\n",
    "# Blackbox Functions\n",
    "enc10_to_idx = []\n",
    "enc10_to_MBR_BLEURT = []\n",
    "enc10_to_MBR_chrF = []\n",
    "# Rankings\n",
    "MBR_BLEURT_index_rank = []\n",
    "MBR_chrF_index_rank = []\n",
    "\n",
    "for idx in tqdm.tqdm(range(num_datapoints)):\n",
    "    idx_datapoint = DATA[idx]\n",
    "\n",
    "    # Encoded Data\n",
    "    _enc_data = np.array(idx_datapoint['enc_candidates'])\n",
    "    enc_candidates.append(_enc_data)\n",
    "    pca = PCA()\n",
    "    _enc_data_10 = pca.fit_transform(_enc_data)[:,:reduced_dim]\n",
    "    enc_candidates10.append(_enc_data_10)\n",
    "\n",
    "    # Scores\n",
    "    _bleurt_scores = np.array([np.round(score, 6)-0.5 for score in idx_datapoint['BLEURT_cand_scores']])\n",
    "    _chrf_scores = np.array([np.round(score, 6)-50 for score in idx_datapoint['CHRF_cand_scores']])\n",
    "    BLEURT_cand_scores.append(_bleurt_scores)\n",
    "    CHRF_cand_scores.append(_chrf_scores)\n",
    "\n",
    "    # MBR Scores\n",
    "    _mbr_bleurt_scores = np.array([np.round(score, 6) for score in idx_datapoint['MBR_BLEURT_cand_scores']])/128 -0.5\n",
    "    _mbr_chrf_scores = np.array([np.round(score, 6) for score in idx_datapoint['MBR_CHRF_cand_scores']])/128 -50\n",
    "    MBR_BLEURT_cand_scores.append(_mbr_bleurt_scores)\n",
    "    MBR_CHRF_cand_scores.append(_mbr_chrf_scores)\n",
    "\n",
    "    # Winner Indexes\n",
    "    _mbr_bleurt_winner_idx = idx_datapoint['MBR_BLEURT_winner_index']\n",
    "    _mbr_chrf_winner_idx = idx_datapoint['MBR_CHRF_winner_index']\n",
    "    MBR_BLEURT_winner_index.append(_mbr_bleurt_winner_idx)\n",
    "    MBR_CHRF_winner_index.append(_mbr_chrf_winner_idx)\n",
    "\n",
    "    # Blackbox Function\n",
    "    _enc10_to_idx = {str(_enc_data_10[i]): i for i in range(128)}\n",
    "    _enc10_to_MBR_BLEURT = {str(enc10):_mbr_bleurt_scores[_enc10_to_idx[str(enc10)]] for enc10 in _enc10_to_idx.keys()}\n",
    "    _enc10_to_MBR_chrF = {str(enc10):_mbr_chrf_scores[_enc10_to_idx[str(enc10)]] for enc10 in _enc10_to_idx.keys()}\n",
    "\n",
    "    enc10_to_idx.append(_enc10_to_idx)\n",
    "    enc10_to_MBR_BLEURT.append(_enc10_to_MBR_BLEURT)\n",
    "    enc10_to_MBR_chrF.append(_enc10_to_MBR_chrF)\n",
    "\n",
    "    # Rankings\n",
    "    _MBR_BLEURT_index_rank = ss.rankdata(_mbr_bleurt_scores)\n",
    "    _MBR_chrF_index_rank = ss.rankdata(_mbr_chrf_scores)\n",
    "    MBR_BLEURT_index_rank.append(_MBR_BLEURT_index_rank)\n",
    "    MBR_chrF_index_rank.append(_MBR_chrF_index_rank)\n",
    "\n",
    "enc_candidates = np.array(enc_candidates)\n",
    "enc_candidates10 = np.array(enc_candidates10)\n",
    "BLEURT_cand_scores = np.array(BLEURT_cand_scores)\n",
    "CHRF_cand_scores = np.array(CHRF_cand_scores)\n",
    "MBR_BLEURT_cand_scores = np.array(MBR_BLEURT_cand_scores)\n",
    "MBR_CHRF_cand_scores = np.array(MBR_CHRF_cand_scores)\n",
    "MBR_BLEURT_winner_index = np.array(MBR_BLEURT_winner_index)\n",
    "MBR_CHRF_winner_index = np.array(MBR_CHRF_winner_index)\n",
    "### Blackbox Function Example Usage\n",
    "# enc10_to_MBR_chrF[0][str(enc_candidates10[0][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJa9Bc4EQaAO"
   },
   "outputs": [],
   "source": [
    "from skopt.learning import GaussianProcessRegressor\n",
    "from skopt.space import Space\n",
    "from skopt.acquisition import gaussian_ei\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhNqn_IoQgiN",
    "outputId": "a6422f8b-299d-40e8-db26-eb34c7b141d6"
   },
   "outputs": [],
   "source": [
    "BASELINE_best_MBR_BLEURT = []\n",
    "BASELINE_best_MBR_BLEURT_rank = []\n",
    "BASELINE_best_BLEURT = []\n",
    "\n",
    "MODEL_best_MBR_BLEURT = []\n",
    "MODEL_best_MBR_BLEURT_rank = []\n",
    "MODEL_best_BLEURT = []\n",
    "\n",
    "for experiment in range(10):\n",
    "    for idx in tqdm.tqdm(range(1000)):\n",
    "        # BLEURT\n",
    "        X = enc_candidates10[idx]\n",
    "        y = MBR_BLEURT_cand_scores[idx]\n",
    "        f = enc10_to_MBR_BLEURT[idx]\n",
    "        #######################\n",
    "        ### Random Baseline ###\n",
    "        #######################\n",
    "        n_samples = 10\n",
    "        initial_indices = np.random.choice(range(len(X)), n_samples, replace=False)\n",
    "        initial_samples = X[initial_indices]\n",
    "        initial_evaluations = [f[str(x)] for x in initial_samples]\n",
    "        best_index_local = np.argmax(initial_evaluations)\n",
    "        best_index = initial_indices[best_index_local]\n",
    "        # Results\n",
    "        best_MBR_BLEURT = MBR_BLEURT_cand_scores[idx][best_index]\n",
    "        best_MBR_BLEURT_rank = MBR_BLEURT_index_rank[idx][best_index]\n",
    "        best_BLEURT = BLEURT_cand_scores[idx][best_index]\n",
    "        # print(\"Baseline - best_MBR_BLEURT:\", best_MBR_BLEURT)\n",
    "        # print(\"Baseline - best_MBR_BLEURT_rank:\", best_MBR_BLEURT_rank)\n",
    "        # print(\"Baseline - best_BLEURT:\", best_BLEURT)\n",
    "        BASELINE_best_MBR_BLEURT.append(best_MBR_BLEURT)\n",
    "        BASELINE_best_MBR_BLEURT_rank.append(best_MBR_BLEURT_rank)\n",
    "        BASELINE_best_BLEURT.append(best_BLEURT)\n",
    "        #####################################################################################\n",
    "        ### Bayesian Optimization with Gaussian Process Regression - Expected Improvement ###\n",
    "        #####################################################################################\n",
    "        n_initial_points = 5\n",
    "        num_iterations = 5\n",
    "        initial_indices = np.random.choice(range(len(X)), n_initial_points, replace=False)\n",
    "        initial_samples = X[initial_indices]\n",
    "        initial_evaluations = [f[str(x)] for x in initial_samples]\n",
    "        # GP model\n",
    "        kernel = ConstantKernel(constant_value=1.0) * RBF(length_scale=1.0)\n",
    "        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5 , normalize_y =False,  alpha=0.00001)\n",
    "        # Train GP Model\n",
    "        gp.fit(initial_samples, initial_evaluations)\n",
    "\n",
    "        for _ in range(num_iterations):\n",
    "            # Current best\n",
    "            current_best = np.max(gp.y_train_)\n",
    "            # Acquisition values\n",
    "            acquisition_values = - gaussian_ei(X, gp, y_opt=current_best, xi=0.01)\n",
    "            # acquisition_values = np.zeros([128]) # Random Baseline\n",
    "            # Filter out previously evaluated points\n",
    "            evaluated_points = set(map(tuple, gp.X_train_))\n",
    "            filtered_acquisition = np.array([acq if tuple(point) not in evaluated_points else -np.inf for point, acq in zip(X, acquisition_values)])\n",
    "            ##########################\n",
    "            # Select the next index (Alternative 1)\n",
    "            # next_index = np.argmax(filtered_acquisition)\n",
    "            # Select the next index (Alternative 2)\n",
    "            p_current = n_initial_points + _ + 100   # Filter out smallest elements p elements\n",
    "            smallest_ten_indices = np.argsort(filtered_acquisition)[:p_current]\n",
    "            for index in smallest_ten_indices:\n",
    "                filtered_acquisition[index] = float('-inf')\n",
    "            valid_indices = [index for index, value in enumerate(filtered_acquisition) if value != float('-inf')] # indices whose corresponding elements are not -inf\n",
    "            next_index = random.choice(valid_indices) #  sample an index from the valid indices\n",
    "            ##########################\n",
    "            # Select the next point\n",
    "            next_point = X[next_index]\n",
    "            # Evaluate the next point\n",
    "            next_evaluation = f[str(next_point)]\n",
    "            # Train GP model including the new point\n",
    "            X_new = np.vstack([gp.X_train_, next_point])\n",
    "            Y_new = np.append(gp.y_train_, next_evaluation)\n",
    "            gp.fit(X_new,Y_new)\n",
    "\n",
    "        # Results\n",
    "        best_evaluation_index_local = np.argmax(gp.y_train_)\n",
    "        best_point = gp.X_train_[best_evaluation_index_local]\n",
    "        best_value = gp.y_train_[best_evaluation_index_local]\n",
    "        best_evaluation_index = enc10_to_idx[idx][str(best_point)]\n",
    "        best_MBR_BLEURT = MBR_BLEURT_cand_scores[idx][best_evaluation_index]\n",
    "        best_MBR_BLEURT_rank = MBR_BLEURT_index_rank[idx][best_evaluation_index]\n",
    "        best_BLEURT = BLEURT_cand_scores[idx][best_evaluation_index]\n",
    "        # print(\"Model best_MBR_BLEURT:\", best_MBR_BLEURT)\n",
    "        # print(\"Model best_MBR_BLEURT_rank:\", best_MBR_BLEURT_rank)\n",
    "        # print(\"Model best_BLEURT:\", best_BLEURT)\n",
    "        MODEL_best_MBR_BLEURT.append(best_MBR_BLEURT)\n",
    "        MODEL_best_MBR_BLEURT_rank.append(best_MBR_BLEURT_rank)\n",
    "        MODEL_best_BLEURT.append(best_BLEURT)\n",
    "        # print('---')\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUtIAIsLUrIe",
    "outputId": "fc172509-d809-4b2b-ffef-89a5071bd3c3"
   },
   "outputs": [],
   "source": [
    "print('BASELINE_best_MBR_BLEURT:',np.mean(BASELINE_best_MBR_BLEURT)+0.5)\n",
    "print('BASELINE_best_MBR_BLEURT_rank:',np.mean(BASELINE_best_MBR_BLEURT_rank))\n",
    "print('BASELINE_best_BLEURT:',np.mean(BASELINE_best_BLEURT)+0.5)\n",
    "\n",
    "print('MODEL_best_MBR_BLEURT:',np.mean(MODEL_best_MBR_BLEURT)+0.5)\n",
    "print('MODEL_best_MBR_BLEURT_rank:',np.mean(MODEL_best_MBR_BLEURT_rank))\n",
    "print('MODEL_best_BLEURT:',np.mean(MODEL_best_BLEURT)+0.5)\n",
    "\n",
    "print('UPPER_BOUND MBR BLEURT:', np.array([MBR_BLEURT_cand_scores[idx][MBR_BLEURT_winner_index[idx]] for idx in range(num_datapoints)]).mean()+0.5)\n",
    "print('UPPER_BOUND RANK:', np.array([MBR_BLEURT_index_rank[idx][MBR_BLEURT_winner_index[idx]]for idx in range(num_datapoints)]).mean())\n",
    "print('UPPER_BOUND BLEURT:', np.array([BLEURT_cand_scores[idx][MBR_BLEURT_winner_index[idx]]for idx in range(num_datapoints)]).mean()+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1Dehc3uUwg5",
    "outputId": "aaf2c093-87d9-439b-aebf-b539e28fac8a"
   },
   "outputs": [],
   "source": [
    "n = len(BASELINE_best_MBR_BLEURT_rank)\n",
    "print(n)\n",
    "print('Baseline is Better', sum([BASELINE_best_MBR_BLEURT_rank[i] > MODEL_best_MBR_BLEURT_rank[i] for i in range(n)]))\n",
    "print('Model is Better', sum([BASELINE_best_MBR_BLEURT_rank[i] < MODEL_best_MBR_BLEURT_rank[i] for i in range(n)]))\n",
    "print('Tie', sum([BASELINE_best_MBR_BLEURT_rank[i] == MODEL_best_MBR_BLEURT_rank[i] for i in range(n)]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
